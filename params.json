{
  "name": "Hierarchical Object Detection with Deep Reinforcement Learning",
  "tagline": "Deep Reinforcement Learning Workshop, NIPS 2016",
  "body": "|  ![NIPS 2016 logo][logo-nips] | Paper accepted at [Deep Reinforcement Learning Workshop, NIPS 2016](https://sites.google.com/site/deeprlnips2016/)   |\r\n|:-:|---|\r\n\r\n[logo-nips]: https://github.com/imatge-upc/detection-2016-nipsws/blob/master/logos/nips500x95.png?raw=true \"NIPS 2016 logo\"\r\n\r\n| ![Míriam Bellver][bellver-photo]  | ![Xavier Giro-i-Nieto][giro-photo]  | ![Ferran Marqués][marques-photo]  | ![Jordi Torres][torres-photo]  |\r\n|:-:|:-:|:-:|:-:|:-:|\r\n| [Míriam Bellver][bellver-web]  | [Xavier Giro-i-Nieto][giro-web]  |  [Ferran Marques][marques-web] | [Jordi Torres][torres-web]  |\r\n\r\n\r\n[bellver-web]: https://www.bsc.es/bellver-bueno-miriam\r\n[giro-web]: https://imatge.upc.edu/web/people/xavier-giro\r\n[torres-web]: http://www.jorditorres.org/\r\n[marques-web]:https://imatge.upc.edu/web/people/ferran-marques\r\n\r\n[bellver-photo]:  https://github.com/imatge-upc/detection-2016-nipsws/blob/master/authors/MiriamBellver160x160.jpg?raw=true \"Míriam Bellver\"\r\n[giro-photo]: https://github.com/imatge-upc/detection-2016-nipsws/blob/master/authors/XavierGiro160x160.jpg?raw=true \"Xavier Giro-i-Nieto\"\r\n[marques-photo]: https://github.com/imatge-upc/detection-2016-nipsws/blob/master/authors/FerranMarques160x160.jpg?raw=true \"Ferran Marques\"\r\n[torres-photo]:  https://github.com/imatge-upc/detection-2016-nipsws/blob/master/authors/JordiTorres.jpg?raw=true  \"Jordi Torres\"\r\n\r\nA joint collaboration between:\r\n\r\n|![logo-bsc] | ![logo-gpi]  |\r\n|:-:|:-:|:-:|\r\n| [Barcelona Supercomputing Center][bsc-web] | [UPC Image Processing Group][gpi-web] |\r\n\r\n[gpi-web]: https://imatge.upc.edu/web/ \r\n[bsc-web]: http://www.bsc.es \r\n\r\n[logo-bsc]:https://github.com/imatge-upc/detection-2016-nipsws/blob/master/logos/bsc320x86.jpg?raw=true \"Barcelona Supercomputing Center\"\r\n[logo-gpi]: https://github.com/imatge-upc/detection-2016-nipsws/blob/master/logos/gpi320x70.png?raw=true \"UPC Image Processing Group\"\r\n\r\n## Publication\r\n### Abstract\r\n\r\n We present a method for performing hierarchical object detection in images guided by a deep reinforcement learning agent. The key idea is to focus on those parts of the image that contain richer information and zoom on them. We train an intelligent agent that, given an image window, is capable of deciding where to focus the attention among five different predefined region candidates (smaller windows). This procedure is iterated providing a hierarchical image analysis.\r\n \r\nWe compare two different candidate proposal strategies to guide the object search: with and without overlap. Moreover, our work compares two different strategies to extract features from a convolutional neural network for each region proposal: a first one that computes new feature maps for each region proposal, and a second one that computes the feature maps for the whole image to later generate crops for each region proposal. \r\n\r\nExperiments indicate better results for the overlapping candidate proposal strategy and a loss of performance for the cropped image features due to the loss of spatial resolution. We argue that, while this loss seems unavoidable when working with large amounts of object candidates, the much more reduced amount of region proposals generated by our reinforcement learning agent allows considering to extract features for each location without sharing convolutional computation among regions.\r\n\r\n\r\n## Code Instructions\r\n\r\nThis python code enables to both train and test each of the two models proposed in the paper. The image zooms model extracts features for each region visited, whereas the pool45 crops model extracts features just once and then ROI-pools features for each subregion. In this section we are going to describe how to use the code.\r\n\r\n### Setup\r\n\r\nFirst of all the weights of VGG-16 should be downloaded from the following link [VGG-16 weights]. If you want to use some pre-trained models for the Deep Q-network, they can be downloaded in the following links [Image Zooms model] and [Pool45 Crops model].You should also create two folders in the root of the project, called models_image_zooms and models_pool45_crops, and store inside them the corresponding weights. \r\n\r\n\r\n[VGG-16 weights]: https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing\r\n[Image Zooms model]: \r\n[Pool45 Crops model]:\r\n\r\n\r\n### Usage\r\n\r\n##### Training\r\n\r\nWe will follow as example how to train the Image Zooms model, that is the one that achieves better results. The instructions are equal for training the Pool45 Crops model. The script is image_zooms_training.py, and first the path to the database should be configured:\r\n\r\nPATHS\r\n\r\nThe enables checkpointing, so you should indicate which epoch you are going to train. If you are training it from scratch, then the training command should be:\r\n\r\npython image_zooms_training.py -n 0\r\n\r\nThere are many options that can be changed to test different configurations:\r\n\r\nNumber of steps: For how many steps you want your agent to search for an object in an image.\r\n\r\nSubregion scale: The scale of the subregions in the hierarchy, compared to its ancestor. Default value is 3/4, that denoted good results in our experiments, but it can easily be set. Take into consideration that the subregion scale and the number of steps is very correlated, if the subregion scale is high, then you will probably require more steps to find objects.\r\n\r\nDrawing: \r\n\r\n\r\n##### Testing\r\n\r\nIn this case, you should use the script image_zooms_testing.py. You should also configure the paths to indicate which weights you want to use. In this case, you should only run the command python image_zooms_testing.py. It is recommended that for testing you put bool_draw = 1, so you can observe the visualizations of the object search sequences. \r\n\r\n\r\n\r\n## Acknowledgements\r\n\r\nWe would like to especially thank Albert Gil Moreno and Josep Pujal from our technical support team at the Image Processing Group at the UPC.\r\n\r\n| ![AlbertGil-photo]  | ![JosepPujal-photo]  |\r\n|:-:|:-:|\r\n| [Albert Gil](AlbertGil-web)  |  [Josep Pujal](JosepPujal-web) |\r\n\r\n[AlbertGil-photo]: https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/authors/AlbertGil.jpg \"Albert Gil\"\r\n[JosepPujal-photo]: https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/authors/JosepPujal.jpg \"Josep Pujal\"\r\n\r\n[AlbertGil-web]: https://imatge.upc.edu/web/people/albert-gil-moreno\r\n[JosepPujal-web]: https://imatge.upc.edu/web/people/josep-pujal\r\n\r\n|   |   |\r\n|:--|:-:|\r\n|  We gratefully acknowledge the support of [NVIDIA Corporation](http://www.nvidia.com/content/global/global.php) with the donation of the GeoForce GTX [Titan Z](http://www.nvidia.com/gtx-700-graphics-cards/gtx-titan-z/) and [Titan X](http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-titan-x) used in this work. |  ![logo-nvidia] |\r\n|  The Image ProcessingGroup at the UPC is a [SGR14 Consolidated Research Group](https://imatge.upc.edu/web/projects/sgr14-image-and-video-processing-group) recognized and sponsored by the Catalan Government (Generalitat de Catalunya) through its [AGAUR](http://agaur.gencat.cat/en/inici/index.html) office. |  ![logo-catalonia] |\r\n|  This work has been developed in the framework of the project [BigGraph TEC2013-43935-R](https://imatge.upc.edu/web/projects/biggraph-heterogeneous-information-and-graph-signal-processing-big-data-era-application), funded by the Spanish Ministerio de Economía y Competitividad and the European Regional Development Fund (ERDF).  | ![logo-spain] | \r\n\r\n\r\n[logo-nvidia]: https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/nvidia.jpg \"Logo of NVidia\"\r\n[logo-catalonia]: https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/generalitat.jpg \"Logo of Catalan government\"\r\n[logo-spain]: https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/MEyC.png \"Logo of Spanish government\"\r\n\r\n\r\n## Contact\r\n\r\nIf you have any general doubt about our work or code which may be of interest for other researchers, please use the [public issues section](https://github.com/imatge-upc/detection-2016-nipsws/issues) on this github repo. Alternatively, drop us an e-mail at <mailto:miriam.bellver@bsc.es> and <mailto:xavier.giro@upc.edu>.\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}